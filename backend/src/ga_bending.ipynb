{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qU6F_3itDJlQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load original dataset\n",
        "df = pd.read_csv(\"bending_machine_data.csv\")  # Replace with actual dataset path\n",
        "target_col = \"result\"  # Define the target column\n"
      ],
      "metadata": {
        "id": "PE7v42b1D60W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for GAN\n",
        "X = df.drop(columns=[target_col]).values\n",
        "y = df[target_col].values\n",
        "input_dim = X.shape[1]"
      ],
      "metadata": {
        "id": "RNfn7PcbD_FK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GAN components\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, output_dim),\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.model(z)"
      ],
      "metadata": {
        "id": "6uqTL982EJyr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "6C63v-YlELJ_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "generator = Generator(input_dim, input_dim)\n",
        "discriminator = Discriminator(input_dim)\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator(input_dim, input_dim)\n",
        "discriminator = Discriminator(input_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.001)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "8swQ0x5TEPPy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(epochs=500, batch_size=32):\n",
        "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_data in dataloader:\n",
        "            real_data = real_data[0]\n",
        "            batch_size = real_data.size(0)\n",
        "            real_labels = torch.ones(batch_size, 1)\n",
        "            fake_labels = torch.zeros(batch_size, 1)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_d.zero_grad()\n",
        "            outputs = discriminator(real_data)\n",
        "            loss_real = criterion(outputs, real_labels)\n",
        "            loss_real.backward()\n",
        "\n",
        "            z = torch.randn(batch_size, input_dim)\n",
        "            fake_data = generator(z)\n",
        "            outputs = discriminator(fake_data.detach())\n",
        "            loss_fake = criterion(outputs, fake_labels)\n",
        "            loss_fake.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_g.zero_grad()\n",
        "            outputs = discriminator(fake_data)\n",
        "            loss_g = criterion(outputs, real_labels)\n",
        "            loss_g.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss {loss_real+loss_fake:.4f}, G Loss {loss_g:.4f}\")\n",
        "\n",
        "train_gan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv9j0-8eESpw",
        "outputId": "2b37c211-004a-4221-e767-12bb0db89395"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: D Loss 0.6689, G Loss 0.7402\n",
            "Epoch 50: D Loss 2.1878, G Loss 3.4207\n",
            "Epoch 100: D Loss 0.3312, G Loss 2.8698\n",
            "Epoch 150: D Loss 0.3494, G Loss 3.0417\n",
            "Epoch 200: D Loss 1.7184, G Loss 1.0367\n",
            "Epoch 250: D Loss 1.8110, G Loss 0.7176\n",
            "Epoch 300: D Loss 1.8005, G Loss 0.9141\n",
            "Epoch 350: D Loss 1.4108, G Loss 0.7899\n",
            "Epoch 400: D Loss 1.6202, G Loss 0.5215\n",
            "Epoch 450: D Loss 1.3029, G Loss 0.6038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "z = torch.randn(500, input_dim)  # Generate 500 synthetic samples\n",
        "synthetic_data = generator(z).detach().numpy()"
      ],
      "metadata": {
        "id": "DAxu9DJcEaqw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create augmented dataset\n",
        "synthetic_df = pd.DataFrame(synthetic_data, columns=df.drop(columns=[target_col]).columns)\n",
        "synthetic_df[target_col] = np.random.uniform(y.min(), y.max(), size=synthetic_df.shape[0])\n",
        "augmented_df = pd.concat([df, synthetic_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "q7cOlAS7EaxA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create augmented dataset\n",
        "augmented_df = pd.concat([df, synthetic_df], ignore_index=True)\n",
        "augmented_df.to_csv(\"ga_augmented_data.csv\", index=False)\n",
        "synthetic_df.to_csv(\"ga_synthetic_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "ZHAF0RYAGDOP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Rk2n26oLGkT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}